{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Unsupervised Learning:\n",
    "Unsupervised learning is a branch of machine learning where the goal is to discover patterns, structures, or relationships in the data without any labeled target outputs. Unlike supervised learning, where the model learns from labeled data, unsupervised learning focuses on working with unlabeled data to find inherent structures within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: Grouping Similar Data Points:\n",
    "**Clustering** is a common unsupervised learning technique used to group similar data points together based on certain features or characteristics. The goal is to partition the data into clusters where data points within the same cluster are more similar to each other compared to points in other clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"data/classification_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K_Means Clustering\n",
    "kmeans = KMeans(n_clusters= 3, random_state=42)\n",
    "data['cluster'] = kmeans.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize the clusters in 2D plot\n",
    "plt.scatter(data['feature1'], data['feature2'], data['cluster'], cmap='rainbow')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction : Reducing Features While Retaining Information:\n",
    "Dimensionality reduction is another crucial unsupervised learning technique that aims to reduce the number of features (dimensions) in a dataset while preserving its essential information. This is particularly useful for simplifying complex datasets, speeding up computations, and avoiding overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appply PCA for dimnesionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize the reduce dimensional data\n",
    "plt.scatter(data[:,0], data_pca[0:1])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Principla Dimensionality Reduction')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
